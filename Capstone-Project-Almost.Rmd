---
title: "An Example Using the Tufte Style"
author: "John Smith"
output:
  tufte::tufte_html: default
  html_document:
    df_print: paged
  tufte::tufte_handout: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(httr)
library(jsonlite)
library(tidyverse)
library(ckanr)
library(rvest)
library(RCurl)
library(readr)
library(rio)
library(ggplot2)
library(patchwork)
 library(stringr)

```

#Safety in Buenos Aires

Safety is a big issue all around Latin America. The way we perceive safety when walking around the streets, going back home late at night, and taking care of our personal belongings is something people in developed countries take for granted. Instead, for Latin-Americans these constitute a permanent struggle.
This was the main reason why I was motivated to research about Buenos Airesâ€™ crime records and analyze it. Thanks to Buenos Aires Government Open Data Portal, I could access a pretty complete dataset in order to develop my Capstone project.
For the scope of the project, I accessed public data through the CKAN API, enabling the free download, usage and treatment of public data from repositories and websites. 
 
 The roadmap of my Capstone Project was: 

1. Download public available information on Buenos Aires Crime Reports

2. Organize and tidy up the datasets

3. Insights about Crime Reports in Buenos Aires

5. Conclusions


#1. Download public available information on Buenos Aires' Crime Reports

I installed library(ckanr) in order to be able to access the databases that were of my interest.
I read the instructions and followed them step by step in order to access the CSV that was linked on the page. Therefore, through R I connected to the API, by pasting the link, the package and the id of the dataset. I used the "GET" command to make the API request, and then I checked the status_code on the page. Then, I assigned the JSON file to a vector and from there got the results of the links linked to the package and ID of datasets. Consequently, I downloaded each dataset one by one, calling the links with the command csv.

```{r}
#Import the information
url <- paste0("https://data.buenosaires.gob.ar/api/3/action/",
              "package_show?",
              "id=delitos")

page <- GET(url) # API request
status_code(page) # # Check that the call is successful

datalist <- fromJSON(url) 
data <- datalist$result$resources$url
(data) 

datasets <- as.vector(unlist(data))
(datasets)

BA17 <- read_csv(data[[2]])
problems2 <- problems
BA18 <- read_csv(data[[3]])
BA19 <- read_csv(data[[4]])

problems19 <- problems

write.csv(BA17, "Baires17.csv")
write.csv(BA18, "Baires18.csv")
write.csv(BA19, "Baires19.csv")

```

I downloaded the file so I could start working with the file on my computer. When downloading the file I discovered there were parsing problems and so I assigned these problems to different vector. Then, I saved all files on my computer.
When inspecting the documents, I found out the information is structured as follows: 
Each row (observation) is a crime record.
The dataset counts with 10 columns:
  id = col_double(),
  fecha = col_character(),
  franja_horaria = col_double(),
  tipo_delito = col_character(),
  subtipo_delito = col_logical(),
  cantidad_registrada = col_logical(),
  comuna = col_double(),
  barrio = col_character(),
  lat = col_double(),
  long = col_double()

Then, I found out the parsing problems relied on the column "subtipo delito" for the file of the 2019 Crimes, that is a logical column where it should actually be a "character" variable that should relate to a subcategory of "tipo_delito". 
In the "problems" dataset, I found there were 6 columns structured as a report where each observation is the error the parsing process approached: 
x1: number of observation, thus error.
row: number of row to which is associated in the original dataset
col: column that has had the trouble
expected: possible values to which the error should be 
actual: the value it should take on the column. 

Therefore my approach to fix the parsing problem was combining both files accurately by matching the "problematic" number of row with the corresponding number of row, thus observation or crime record.

However, when I read precisely the problems dataset, I found out that the parsing problems were also associated to the fact that there is actually a column used to register the quantity. Actually, on the dataset, each observation is a row, therefore a column saying the quantity of registered crimes makes no sense. Then, given the large number of observations and the scope of the project, I decided to keep just the character strings, in order to retrieve the "subcategory" of crime, that after skimming the document I discovered were the crimes related to car thefts.

```{r}

Crimes_BA19 <- BA19%>% 
  select(id, fecha, franja_horaria, tipo_delito, subtipo_delito, comuna, barrio) 

Crimes_BA18 <- BA18%>% 
  select(id, fecha, franja_horaria, tipo_delito, subtipo_delito, comuna, barrio) 

Crimes_BA17 <- BA17%>% 
  select(id, fecha, franja_horaria, tipo_delito, subtipo_delito, comuna, barrio) 
```

To start with my analysis and based on my perception of unsafety in Buenos Aires, I started by handling the "franja horaria" variable and performing a mutate in order to divide into groups the different parts of the day to understand if there is any relationship between the timeframe and the crimes happened.

```{r}
Crimes_BA <- as_tibble(Crimes_BA)

Crimes_BA  %>% 
  group_by(franja_horaria, timeframe) %>% 
  count()

Crimes_BA19 <- Crimes_BA19 %>% 
  mutate(timeframe = ifelse (franja_horaria >= 7 & franja_horaria <= 13, "Morning",
              ifelse (franja_horaria > 13 & franja_horaria <= 18, "Afternoon", 
               ifelse(franja_horaria > 18 & franja_horaria < 22, "Evening", "Night"))))

Crimes_BA18 <- Crimes_BA18 %>% 
  mutate(timeframe = ifelse (franja_horaria >= 7 & franja_horaria <= 13, "Morning",
              ifelse (franja_horaria > 13 & franja_horaria <= 18, "Afternoon", 
               ifelse(franja_horaria > 18 & franja_horaria < 22, "Evening", "Night"))))

Crimes_BA17 <- Crimes_BA17 %>% 
  mutate(timeframe = ifelse (franja_horaria >= 7 & franja_horaria <= 13, "Morning",
              ifelse (franja_horaria > 13 & franja_horaria <= 18, "Afternoon", 
               ifelse(franja_horaria > 18 & franja_horaria < 22, "Evening", "Night"))))

```

Giving the timeframe is also associated to the period of the daylight, which changes according to seasons, I decided to dive into the date variable. As mentioned before, the date variable was a character string. Using the package "lubridate", I changed the variable into date, and then I separated the date into three columns. Aware of the fact that the crime records of this dataset are all records of 2019, the column "year" is nonsense.


```{r}
is.character(Crimes_BA$fecha)

Crimes_BA19 <- Crimes_BA19 %>%
  separate(fecha, sep="-", into = c("year", "month", "day"))

Crimes_BA19 <- Crimes_BA19 %>%
  separate(fecha, sep="-", into = c("year", "month", "day"))
Crimes_BA18 <- Crimes_BA18 %>%
  separate(fecha, sep="-", into = c("year", "month", "day"))
Crimes_BA17 <- Crimes_BA17 %>%
  separate(fecha, sep="-", into = c("year", "month", "day"))


```

Now, it was time to start seeing the general distribution of my dataset.

```{r}
Distribution19 <- Crimes_BA19 %>%
  group_by(month) %>% 
  count() %>% 
  ggplot(aes(x = month, y = n))+
  geom_col(fill = "#00abff")+
  theme_bw()

Distribution18 <- Crimes_BA18%>%
  group_by(month) %>% 
  count() %>% 
  ggplot(aes(x = month, y = n))+
  geom_col(fill = "#00abff")+
  theme_bw()

Distribution17 <- Crimes_BA17%>%
  group_by(month) %>% 
  count() %>% 
  ggplot(aes(x = month, y = n))+
  geom_col(fill = "#00abff")+
  theme_bw()

(Distribution19 | Distribution18 | Distribution17)

```

As we can see, the distirbution does not suffer variations during the year and, on the contrary to what I have thought beforehand, the distribution does not vary according to season.
What happens along the day and timeframe?

```{r}
Timeframes19 <- Crimes_BA19 %>% 
  group_by(timeframe, comuna, month) %>% 
  count() %>% 
  na.omit() %>% 
  ggplot(aes(x = timeframe, y = n))+
  geom_col(position = "dodge", fill = "#00abff")+
  theme_bw()

Timeframes18 <- Crimes_BA18 %>% 
  group_by(timeframe, comuna, month) %>% 
  count() %>% 
  na.omit() %>% 
  ggplot(aes(x = timeframe, y = n))+
  geom_col(position = "dodge", fill = "#00abff")+
  theme_bw()

Timeframes17 <- Crimes_BA17 %>% 
  group_by(timeframe, comuna, month) %>% 
  count() %>% 
  na.omit() %>% 
  ggplot(aes(x = timeframe, y = n))+
  geom_col(position = "dodge", fill = "#00abff")+
  theme_bw()

(Timeframes19 | Timeframes18 | Timeframes17)

```

As we can see, the majority of the crimes recorded happen during the night, therefore between X and X hour.

About types of crimes, I found out that

```{r}
Crimes_BA %>% 
  group_by(tipo_delito, subtipo_delito) %>% 
  na.omit() %>% 
  count() %>% 
  ggplot(aes(x = tipo_delito, y = n, color = subtipo_delito, fill = subtipo_delito))+
  coord_flip()+
  geom_col(position="stack")+
theme_bw()
```

Then, I was curious about the different areas in Buenos Aires. Therefore I decided to group the dataset by comnua, to discover how was the distribution geographically speaking.

```{r}
Crimes_BA %>%
  group_by(comuna) %>% 
  count() %>% 
  ggplot()+
  geom_col(aes(x = comuna, y = n), position = "dodge", fill = "#00abff")+
  theme(legend.position = "top")
```

As we can see, the most dangerous comuna is the comuna "1" followed by the  third and the fourth one. But which types of crimes happen in these comunas? Are all equally distributed in terms of type of crimes? Let's see

```{r}

labelsmonths <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")

Crimes_BA %>% 
  group_by(tipo_delito, month, comuna, barrio) %>% 
  count()%>%
  ggplot(aes(x = month, y = n, color = tipo_delito, fill = tipo_delito))+
  geom_col(position="dodge")+
scale_x_discrete(labels = labelsmonths, guide = guide_axis(angle = 90))+
theme_bw()
```

Let's see in the three most dangerous "comune".
Using the library patchwork, I combined the three comunes.


```{r}
Comuna1 <- Crimes_BA %>% 
  filter(comuna == "1")%>% 
  group_by(tipo_delito, month) %>% 
  count() %>% 
  ggplot(aes(x = month , y = n, color = tipo_delito, fill = tipo_delito))+
  geom_col(position = "dodge")+
  scale_x_discrete(labels = labelsmonths, "Comuna 1", guide = guide_axis(angle = 90))+
  theme(legend.position = "none")

Comuna3 <- Crimes_BA %>% 
  filter(comuna == "3")%>% 
  group_by(tipo_delito, month) %>% 
  count() %>% 
  ggplot(aes(x = month , y = n, color = tipo_delito, fill = tipo_delito))+
  geom_col(position = "dodge")+
  scale_x_discrete(labels = labelsmonths, "Comuna 3",  guide = guide_axis(angle = 90))+
  theme(legend.position = "none")

Comuna4 <- Crimes_BA %>% 
  filter(comuna == "4")%>% 
  group_by(tipo_delito, month) %>% 
  count() %>% 
  ggplot(aes(x = month , y = n, color = tipo_delito, fill = tipo_delito))+
  geom_col(position = "dodge")+
  scale_x_discrete(labels = labelsmonths, "Comuna 4", guide = guide_axis(angle = 90))+
theme(legend.position = "right",  legend.title = element_text (size=8), legend.text=element_text(size=8))

(Comuna1 | Comuna3 | Comuna4)

```



