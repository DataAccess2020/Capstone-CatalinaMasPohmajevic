---
title: "An Example Using the Tufte Style"
author: "John Smith"
output:
  tufte::tufte_html: default
  html_document:
    df_print: paged
  tufte::tufte_handout: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(httr)
library(jsonlite)
library(tidyverse)
library(ckanr)
library(rvest)
library(RCurl)
library(readr)
library(rio)
library(ggplot2)
library(patchwork)
 library(stringr)

```

#Safety in Buenos Aires

Safety is a big issue all around Latin America. The way we perceive safety when walking around the streets, going back home late at night, and taking care of our personal belongings is something people in developed countries take for granted. Instead, for Latin-Americans these constitute a permanent struggle.
Back in August 2019 I moved to Milan, where I settled and where now I almost take for granted my safety. Therefore, my research proposal along this Capstone project is to focus on Crime Records publicly available and make a comparison of Crime Records in both cities, Buenos Aires and Milan.


To start with my research I found out that the majority of governments put available open public data through the CKAN API, enabling the free download, usage and treatment of public data from repositories and websites. Thanks to both cities' Government Open Data Portals and through this API, I was able to access the datasets to develop my project.
 
 The roadmap of my Capstone Project was: 

1. Download public available information on Buenos Aires and Milan Databases

2. Organize and tidy up the datasets

3. Compare both cities by quantity of crimes reported and crime categories 

4. Crime Rates / Inhabitants in the city

5. Conclusions


#1. Download public available information on Buenos Aires and Milan Databases 

I installed library(ckanr) in order to be able to access the databases that were of my interest.
I started by looking at the information of Buenos Aires.
I read the instructions and followed them step by step in order to access the CSV that was linked on the page. Therefore, through R I connected to the API, by pasting the link, the package and the id of the dataset. I used the "GET" command to make the API request, and then I checked the status_code on the page. Then, I assigned the JSON file to a vector and from there got the results of the links linked to the package and ID of datasets. Consequently, I knew the most recent dataset was the last one, therefore the 4th link, and I called the fourth link using the command read_csv. 

```{r}
#Import the information
url <- paste0("https://data.buenosaires.gob.ar/api/3/action/",
              "package_show?",
              "id=delitos")

page <- GET(url) # API request
status_code(page) # # Check that the call is successful

datalist <- fromJSON(url) 
data <- datalist$result$resources$url
(data) 

datasets <- as.vector(unlist(data))
(datasets)

Dataset <- read_csv(data[[4]])

write.csv(Dataset, "Baires.csv")

Problems <- problems(Dataset)

```

I downloaded the file so I could start working with the file on my computer. When downloading the file I discovered there were parsing problems and so I assigned these problems to a vector. Then, I saved both files on my computer.
When inspecting the documents, I found out the information is structured as follows: 
In the "Baires" dataset, each row (observation) is a crime record.
The dataset counts with 10 columns:
  id = col_double(),
  fecha = col_character(),
  franja_horaria = col_double(),
  tipo_delito = col_character(),
  subtipo_delito = col_logical(),
  cantidad_registrada = col_logical(),
  comuna = col_double(),
  barrio = col_character(),
  lat = col_double(),
  long = col_double()

Then, I found out the parsing problems relied on the column "subtipo delito" that is a logical column where it should actually be a "character" variable that should relate to a subcategory of "tipo_delito". 
In the "problems" dataset, I found there were 6 columns structured as a report where each observation is the error the parsing process approached: 
x1: number of observation, thus error.
row: number of row to which is associated in the original dataset
col: column that has had the trouble
expected: possible values to which the error should be 
actual: the value it should take on the column. 

Therefore my approach to fix the parsing problem was combining both files accurately by matching the "problematic" number of row with the corresponding number of row, thus observation or crime record.

However, when I read precisely the problems dataset, I found out that the parsing problems were also associated to the fact that there is actually a column used to register the quantity. Actually, on the dataset, each observation is a row, therefore a column saying the quantity of registered crimes makes no sense. Then, given the large number of observations and the scope of the project, I decided to keep just the character strings, in order to retrieve the "subcategory" of crime, that after skimming the document I discovered were the crimes related to car thefts.

```{r}

write.csv(Dataset, "Baires.csv")
write.csv(Problems, "Problems.csv")

Dataset <- read_csv("Baires.csv")

Crimes_BA <- data.frame()

Crimes_BA <- Dataset %>% 
  select(X1, id, fecha, franja_horaria, tipo_delito, subtipo_delito, comuna, barrio) 

Crimes_BA$Subtipo <- ifelse(Subtipo_Delito$row %in% Crimes_BA$X1, paste0(Subtipo_Delito$actual), "NA")

Dataset <- Dataset[,-7]  

Problems$row <- as.numeric(Problems$row)
Dataset$X1 <- as.numeric(Dataset$X1)

Dataset$row <- 1:nrow(Dataset)


Problems$row <- as.numeric(Problems$row)
Dataset$row <- as.numeric(Dataset$row)

Crimes_BA <- Crimes_BA %>% 
  mutate(subtipo_delito = ifelse (X1 %in% Problems$row, Problems$actual, "NA"))

Crimes_BA$subtipo_delito <- gsub('[[:digit:]]+', 'NA', Crimes_BA$subtipo_delito)


```

To start with my analysis and based on my perception of unsafety in Buenos Aires, I started by handling the "franja horaria" variable and performing a mutate in order to divide into groups the different parts of the day to understand if there is any relationship between the timeframe and the crimes happened.

```{r}

Crimes_BA <- Crimes_BA %>% 
  mutate(timeframe = ifelse (franja_horaria >= 7 & franja_horaria <= 13, "Morning",
              ifelse (franja_horaria > 13 & franja_horaria <= 18, "Afternoon", 
               ifelse(franja_horaria > 18 & franja_horaria < 22, "Evening", "Night"))))

Crimes_BA <- as_tibble(Crimes_BA)

Crimes_BA  %>% 
  group_by(franja_horaria, timeframe) %>% 
  count()

```

Giving the timeframe is also associated to the period of the daylight, which changes according to seasons, I decided to dive into the date variable. As mentioned before, the date variable was a character string. Using the package "lubridate", I changed the variable into date, and then I separated the date into three columns. Aware of the fact that the crime records of this dataset are all records of 2019, the column "year" is nonsense.


```{r}
is.character(Crimes_BA$fecha)
Crimes_BA$fecha <- as.Date.character(Crimes_BA$fecha, format = c("%d-%m-%Y"))

Crimes_BA <- Crimes_BA %>%
  separate(fecha, sep="-", into = c("year", "month", "day"))

```

Now, it was time to start seeing the general distribution of my dataset.

```{r}
Crimes_BA %>%
  group_by(month) %>% 
  count() %>% 
  ggplot(aes(x = month, y = n))+
  geom_col(fill = "#00abff")+
  theme_bw()
```

As we can see, the distirbution does not suffer variations during the year and, on the contrary to what I have thought beforehand, the distribution does not vary according to season.
What happens along the day and timeframe?

```{r}
Crimes_BA %>% 
  group_by(timeframe, comuna, month) %>% 
  count() %>% 
  na.omit() %>% 
  ggplot(aes(x = timeframe, y = n))+
  geom_col(position = "dodge", fill = "#00abff")+
  theme_bw()
```

As we can see, the majority of the crimes recorded happen during the night, therefore between X and X hour.

About types of crimes, I found out that

```{r}
Crimes_BA %>% 
  group_by(tipo_delito, subtipo_delito) %>% 
  na.omit() %>% 
  count() %>% 
  ggplot(aes(x = tipo_delito, y = n, color = subtipo_delito, fill = subtipo_delito))+
  coord_flip()+
  geom_col(position="stack")+
theme_bw()
```

Then, I was curious about the different areas in Buenos Aires. Therefore I decided to group the dataset by comnua, to discover how was the distribution geographically speaking.

```{r}
Crimes_BA %>%
  group_by(comuna) %>% 
  count() %>% 
  ggplot()+
  geom_col(aes(x = comuna, y = n), position = "dodge", fill = "#00abff")+
  theme(legend.position = "top")
```

As we can see, the most dangerous comuna is the comuna "1" followed by the  third and the fourth one. But which types of crimes happen in these comunas? Are all equally distributed in terms of type of crimes? Let's see

```{r}

labelsmonths <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")

Crimes_BA %>% 
  group_by(tipo_delito, month, comuna, barrio) %>% 
  count()%>%
  ggplot(aes(x = month, y = n, color = tipo_delito, fill = tipo_delito))+
  geom_col(position="dodge")+
scale_x_discrete(labels = labelsmonths, guide = guide_axis(angle = 90))+
theme_bw()
```

Let's see in the three most dangerous "comune".
Using the library patchwork, I combined the three comunes.


```{r}
Comuna1 <- Crimes_BA %>% 
  filter(comuna == "1")%>% 
  group_by(tipo_delito, month) %>% 
  count() %>% 
  ggplot(aes(x = month , y = n, color = tipo_delito, fill = tipo_delito))+
  geom_col(position = "dodge")+
  scale_x_discrete(labels = labelsmonths, "Comuna 1", guide = guide_axis(angle = 90))+
  theme(legend.position = "none")

Comuna3 <- Crimes_BA %>% 
  filter(comuna == "3")%>% 
  group_by(tipo_delito, month) %>% 
  count() %>% 
  ggplot(aes(x = month , y = n, color = tipo_delito, fill = tipo_delito))+
  geom_col(position = "dodge")+
  scale_x_discrete(labels = labelsmonths, "Comuna 3",  guide = guide_axis(angle = 90))+
  theme(legend.position = "none")

Comuna4 <- Crimes_BA %>% 
  filter(comuna == "4")%>% 
  group_by(tipo_delito, month) %>% 
  count() %>% 
  ggplot(aes(x = month , y = n, color = tipo_delito, fill = tipo_delito))+
  geom_col(position = "dodge")+
  scale_x_discrete(labels = labelsmonths, "Comuna 4", guide = guide_axis(angle = 90))+
theme(legend.position = "right",  legend.title = element_text (size=8), legend.text=element_text(size=8))

(Comuna1 | Comuna3 | Comuna4)

```

For downloading the information related to Milan Crime Reports, I accessed the API and through a similar process I downloaded the csv file. I discovered the data was much pooorer and that I could not do the in-depth analysis I wanted. However, I decided to redirect my analysis towards a more quantitative kind of project where to confront the number and types of crimes in both Buenos Aires and Milan.

```{r}

url2 <- ("https://dati.comune.milano.it/api/3/action/datastore_search?q=2019&resource_id=8b03b9f2-f2d7-4408-b439-bc6efc093cff")

page2 <- GET(url2) # API request
status_code(page2) # # Check that the call is successful

datalist <- fromJSON(url2) 
Milano_2019 <- datalist$result$records
view(Milano_2019) 
as.data.frame(Milano_2019)
view(Milano_2019)
head(Milano_2019)
download.file("https://dati.comune.milano.it/api/3/action/datastore_search?q=2019&resource_id=8b03b9f2-f2d7-4408-b439-bc6efc093cff", "Milano.csv")
```

In this dataset, the information is structured as follows:

Every record is a type of crime denounced, having the following variables:
id:
anno_rilevamento_reato:
Crimes Denounced:
Count:
Rank: 


```{r}


```
For making it easier to handle I changed the names of the variables to english.

```{r}
summary(Milano_2019)
names(Milano_2019)[3] <- "Crimes Denounced"
head(Milano_2019)
names(Milano_2019)[4] <- "Count"
```

The last observation of the data frame was a sum up of all the observations, therefore I decided to delete the row.

```{r}
Milan_2019 <- Milano_2019 %>% 
  slice(-c(56))
Milan_2019 = na.omit(Milan_2019)
Milan_2019$Count <- as.numeric(Milan_2019$Count)
```

Since the dataset is structured in a way where each observation is a crime category, I thought it could be interesting to unify criteria and group crimes in broader categories. For doing this I created another variable where using "grepl" I matched the different types of crimes with the ones listed on the dataset.

```{r}
Milan_2019 <- Milan_2019 %>% 
  mutate(crime_category = ifelse(grepl("Omicidi", `Crimes Denounced`), "Omicidi",
                                 ifelse(grepl("Furti", `Crimes Denounced`), "Furti",
                                        ifelse(grepl("furti", `Crimes Denounced`), "Furti",
                                               ifelse(grepl( "Rapine", `Crimes Denounced`),"Rapine",
                                                      ifelse(grepl( "Incendi", `Crimes Denounced`),"Incendi",
                                                             `Crimes Denounced`))))))
```

Once categorized the crimes, I decided to delete the observations where "count" was equal to 0, therefore that there was no record of that crime in the city of Milan. Then, I grouped the crimes by number of counts, in order to understand which were the most frequent categories of crimes reported in Milan.


```{r}
summary(Milan_2019$Count)

Milan_2019 <- Milan_2019 %>% 
  filter(Count > 0) %>% 
  mutate(countgrouped = ifelse(Count < 150, "Seldom Crimes", 
                               ifelse(Count < 3000, "Rare Crimes",
                                  ifelse(Count < 6000, "Occasional Crimes",
                                         ifelse(Count < 10000, "Often Crimes",
                                                "Regular Crimes")))))
                            
```


```{r}
```