---
title: "Capstone Project: Security Analysis in CABA, 2017-2019"
subtitle: Data Access Course | Daps& CO, Università degli Studi di Milano
author: "Catalina Mas Pohmajevic"
date: "25/02/2021"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
---

<h2>Safety in Buenos Aires</h2>

Safety is a big issue all around Latin America. The way we perceive safety when walking around the streets, going back home late at night, and taking care of our personal belongings is something people in developed countries take for granted. Instead, for Latin-Americans these constitute a permanent struggle.
This was the main reason why I was motivated to research about Buenos Aires’ crime records and analyze them. Thanks to Buenos Aires Government Open Data Portal, I could access a pretty complete dataset in order to develop my Capstone Project.
For the scope of the project, I accessed public data through the CKAN API, which enables the free download, usage and treatment of public data from public repositories and websites. 
 
I traced the roadmap of my Capstone Project as follows:

1. Download public available data on Buenos Aires Crime Reports

2. Organize and tidy up the datasets

3. Analyze insights about Crime Reports in Buenos Aires

5. Conclusions


<h4>1. Download public available information on Buenos Aires' Crime Reports</h4>

To begin with my analysis, I installed libraries to do the scraping such as "httr" "jsonlite" "rvest" Rcurl" "readr" and "ckanr".
Ckanr is the package that would allow me to access the CKAN API, an API used by governments that enables the free download, usage and treatment of public data from their repositories or websites.
I also added the libraries that would allow me to tidy up and manage the datasets such as tidyverse, rio, stringr, ggplot and patchwork for graphics.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 10, fig.height = 6,
                      warning = FALSE, message = FALSE)
library(httr)
library(jsonlite)
library(ckanr)
library(rvest)
library(RCurl)
library(readr)
library(tidyverse)
library(rio)
library(stringr)
library(ggplot2)
library(patchwork)
library(leaflet)
library(maps)
library(leaflet.extras)
library(leaflet)
library(leafsync)
library(rmdfiltr)
library(devtools)
```

The first step was to download the datasets.
I connected to the CKAN API, by pasting the link, the package and the id of the dataset. I used the "GET" command to make the API request, and then I checked the status_code on the page. Then, I assigned the JSON file to a vector and from there got the results of the URLs linked to the package and ID of datasets. Consequently, I downloaded each dataset one by one, calling the links with the command read_csv.

```{r}
#Import the datasets
url <- paste0("https://data.buenosaires.gob.ar/api/3/action/",
              "package_show?",
              "id=delitos")

page <- GET(url) # API request
status_code(page) # # Check that the call is successful

datalist <- fromJSON(url) 
data <- datalist$result$resources$url
(data) 

datasets <- as.vector(unlist(data))
(datasets)

BA17 <- read_csv(data[[2]])
BA18 <- read_csv(data[[3]])
BA19 <- read_csv(data[[4]])
problems19 <- problems(BA19)

```

When inspecting the documents, I found out the information is structured as follows: 
Each observation (row) is a crime record.
The dataset counts with 10 columns:
  id = col_double(),
  fecha = col_character(),
  franja_horaria = col_double(),
  tipo_delito = col_character(),
  subtipo_delito = col_logical(),
  cantidad_registrada = col_logical(),
  comuna = col_double(),
  barrio = col_character(),
  lat = col_double(),
  long = col_double()
There were parsing problems when downloading the 2019 dataset, on the column “subtipo delito”.
While for the datasets of 2017 and 2018 the column “subtipo delito” was a character column, for the 2019 dataset was a logical column the program was not able to download. As R suggested running the “problems(…)” command to see what was causing the issue, I assigned these problems to a different vector.

```{r}
write.csv(BA17, "Baires17.csv")
write.csv(BA18, "Baires18.csv")
write.csv(BA19, "Baires19.csv")
write.csv(problems19, "Problems19.csv")

```

I downloaded and saved the files on my computer so to start working with them locally on my computer, bringing them into the R environment assigning them to a vector.

I tried opening the 2019 dataset with Excel and with Notepad to see the problematic column ("subtipo_delito"), and none of the programs were able to read the values of the column, throwing them as missing values. 
After the many attempts of resolving the issue on R, I accessed the txt version on the Open Data Portal of Buenos Aires finding out the column was empty and so that not obtaining the correct information was a matter of an incorrect uploading of the data or the non-existance of the latter.

All in all, giving the scope of this project, the number of observations in each dataset and the insights I’m interested in obtaining, I decided to drop this variable in the rest of the datasets and just focus on the “type of crime” therefore “tipo_delito” instead of deepening on the “subtype” of crime.

```{r}

BA17 <- read.csv("Baires17.csv")
BA18 <- read.csv("Baires18.csv")
BA19 <- read.csv("Baires19.csv")

```

<h4>2.Organize and tidy up the datasets</h4>

To begin with my analysis I created three new datasets selecting the columns I was interested in from the original datasets. I kept:

id = col_double(),
fecha = col_character(),
timeframe = col_double(),
type of crime = col_character(),
comuna = col_double(),
barrio = col_character()

```{r}

Crimes_BA19 <- BA19%>% 
  select(id, fecha, franja_horaria, tipo_delito, comuna, barrio) 

Crimes_BA18 <- BA18%>% 
  select(id, fecha, franja_horaria, tipo_delito, comuna, barrio) 

Crimes_BA17 <- BA17%>% 
  select(id, fecha, franja_horaria, tipo_delito, comuna, barrio)


```

Based on the collective perception of unsafety in Buenos Aires, I started by handling the "franja horaria" variable. I created a new variable called "timeframe"to group the different hours of the day and see if there is any trend/relationship on the crimes committed and the moment of the day in the city. 

```{r}
Crimes_BA19 <- as_tibble(Crimes_BA19)

Crimes_BA19 <- Crimes_BA19 %>% 
  mutate(timeframe = ifelse (franja_horaria >= 7 & franja_horaria <= 13, "Morning",
              ifelse (franja_horaria > 13 & franja_horaria <= 18, "Afternoon", 
               ifelse(franja_horaria > 18 & franja_horaria < 22, "Evening", "Night"))))

Crimes_BA18 <- Crimes_BA18 %>% 
  mutate(timeframe = ifelse (franja_horaria >= 7 & franja_horaria <= 13, "Morning",
              ifelse (franja_horaria > 13 & franja_horaria <= 18, "Afternoon", 
               ifelse(franja_horaria > 18 & franja_horaria < 22, "Evening", "Night"))))

is.numeric(Crimes_BA17$franja_horaria) 

Crimes_BA17$franja_horaria <- as.numeric(Crimes_BA17$franja_horaria)

Crimes_BA17 <- Crimes_BA17 %>% 
  mutate(timeframe = ifelse (franja_horaria >= 7 & franja_horaria <= 13, "Morning",
              ifelse (franja_horaria > 13 & franja_horaria <= 18, "Afternoon", 
               ifelse(franja_horaria > 18 & franja_horaria < 22, "Evening", "Night"))))

```

Giving the timeframe is also associated to the period of the daylight, which changes according to seasons, I decided to dive into the date variable. 
The date variable was a character string. Using the package "lubridate", I changed the variable into date, and then I separated the date into three columns. 
The date variable for the 2019 dataset was also different than the same variable for the 2017 and 2018 datasets. Therefore, I had to format the dates accordingly.

```{r}

Crimes_BA17$fecha <- lubridate::as_date(Crimes_BA17$fecha)
Crimes_BA18$fecha <- lubridate::as_date(Crimes_BA18$fecha)
Crimes_BA19$fecha <- as.Date(as.character(Crimes_BA19$fecha), format = "%d-%m-%y")


Crimes_BA19 <- Crimes_BA19 %>%
  separate(fecha, sep="-", into = c("year", "month", "day"))
Crimes_BA18 <- Crimes_BA18 %>%
  separate(fecha, sep="-", into = c("year", "month", "day"))
Crimes_BA17 <- Crimes_BA17 %>%
  separate(fecha, sep="-", into = c("year", "month", "day"))
```

<h4>3.Getting insights from my datasets</h4>

After tidying up the datasets I was able to inspect the distribution of the levels of unsafety in the City of Buenos Aires. I created a new dataset where I aggregated the count of crimes per year for then plotting it in a column chart and see if there was an homogeneity among the crimes committed during the period analyzed.

```{r}

Dist19 <- Crimes_BA19 %>%
  group_by(year) %>% 
  count() 
Dist18 <-Crimes_BA18 %>%
  group_by(year) %>% 
  count() 
DistributionYears <- full_join(Dist19, Dist18)
Dist17 <- Crimes_BA17 %>%
  group_by(year) %>% 
  count() 

DistributionYears <- full_join(Dist17, DistributionYears)

DistributionYears %>% 
  ggplot(aes(x = year, y = n))+
  geom_col(fill = "#00abff")+
   scale_x_discrete(guide = guide_axis(angle = 60))+
  theme_bw()+
  theme(axis.text.x=element_text(size=rel(1)))+
  ggtitle('2019')+
    xlab(" ")+
    ylab(" ")
```

We can see that there are no relevant variations upon the number of crimes committed per year. The number of crimes is stable over 120000, however there's been an increase in the crimes in 2018 slightly decreasing in 2019.

Subsequently, I wanted to see if there was any trend of crime commitment related to the time of the year or season.
Using the just-created variable "month" I plotted a graph per year with the distribution of crimes committed in each month. Considering the months of June, July and August to be the winter season in Argentina, I would expect to see a decrease in the crimes reported during these months.
I assigned a vector to "labelsmonths" so to label the months in the graphics I did afterwards. 
I created each graphic in a vector and then combined all three in a single representation.


```{r}
labelsmonths <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")

Distribution19 <- Crimes_BA19 %>%
  group_by(month) %>% 
  count() %>% 
  ggplot(aes(x = month, y = n))+
  geom_col(fill = "#f8766d")+
   scale_x_discrete(labels = labelsmonths, guide = guide_axis(angle = 60))+
  theme_bw()+
  theme(axis.text.x=element_text(size=rel(1)))+
  ggtitle('2019')+
    xlab(" ")+
    ylab(" ")

Distribution18 <- Crimes_BA18%>%
  group_by(month) %>% 
  count() %>% 
  ggplot(aes(x = month, y = n))+
  geom_col(fill = "#7cae00")+
   scale_x_discrete(labels = labelsmonths, guide = guide_axis(angle = 60))+
  theme_bw()+
  theme(axis.text.x=element_text(size=rel(1)))+
    ggtitle('2018')+
   xlab("Month")+
      ylab(" ")


Distribution17 <- Crimes_BA17%>%
  group_by(month) %>% 
  count() %>% 
  ggplot(aes(x = month, y = n))+
  geom_col(fill = "#01bfc4")+
  scale_x_discrete(labels = labelsmonths, guide = guide_axis(angle = 60))+
  theme_bw()+
  theme(axis.text.x=element_text(size=rel(1)))+
    ggtitle('2017')+
    ylab("Number of Crimes")+
  xlab(" ")

Distribution <- (Distribution17 | Distribution18 | Distribution19)
  
  Distribution + plot_annotation(
  title = 'Crimes Recorded among the years in the City of Buenos Aires', theme=theme(plot.title=element_text(size=8))) & theme(text=element_text("mono"))
```

As we can see, the distribution within the months of each year does not suffer remarkable variations and is close to normal. 
Following my hypothesis, there is a variation among the winter months. However, this difference seems not to be significant, given the fact July represents the minimum only in the 2019 graph.For 2017 and 2018, is February the month with the smallest number of crimes reported.
Based on my experience as citizen of Buenos Aires, I wondered about crimes committed in each moment of the day. Usually the shared feeling is that the unsafest moments of the day are around 2 or 3 p.m. and during the night.
To perform this analysis I grouped each dataset by timeframe and month - ommitting missing values - to see the distribution among each moment of the day during the 2017-2019 period.

```{r}

labeltimes <- c("Afternoon", "Morning", "Evening", "Night")

Timeframes17 <- Crimes_BA17 %>% 
  group_by(timeframe, month) %>% 
  count() %>% 
  na.omit() %>% 
  ggplot(aes(x = timeframe, y = n, fill = timeframe))+
  geom_col( position = "dodge")+
  scale_x_discrete(labels = labeltimes, guide = guide_axis(angle = 60))+
  theme_bw()+
  theme(legend.position = "none", axis.text.x=element_text(size=rel(1)))+
    ggtitle('2017')+
    ylim(0,6000)+
    ylab("Number of Crimes")+
  xlab(" ")

Timeframes18 <- Crimes_BA18 %>% 
  group_by(timeframe, month) %>% 
  count() %>% 
  na.omit() %>% 
  ggplot(aes(x = timeframe, y = n, fill = timeframe))+
  geom_col(position = "dodge")+
  scale_x_discrete(labels = labeltimes, guide = guide_axis(angle = 60))+
  theme_bw()+
  theme(legend.position = "none",axis.text.x=element_text(size=rel(1)))+
    ggtitle('2018')+
    ylim(0,6000)+
      ylab("")+
  xlab("Timeframe")

Timeframes19 <- Crimes_BA19 %>% 
  group_by(timeframe, month) %>% 
  count() %>% 
  na.omit() %>% 
  ggplot(aes(x = timeframe, y = n, fill = timeframe))+
  geom_col(position = "dodge")+
  scale_x_discrete(labels = labeltimes, guide = guide_axis(angle = 60))+
  theme_bw()+
  theme(legend.position = "none", axis.text.x=element_text(size=rel(1)))+
  ylim(0,6000)+
    ggtitle('2019')+
      ylab(" ")+
  xlab(" ")

Graph_Timeframes <-  ( Timeframes17 | Timeframes18 | Timeframes19)

Graph_Timeframes +
  plot_annotation(
  title = 'Crimes Recorded per Timeframe in the City of Buenos Aires', theme=theme(plot.title=element_text(size=8))) & theme(text=element_text("mono"))

```

During 2017 and 2019, the majority of the crimes were committed during the Night and Evening. Instead, for 2018, it was the afternoon the unsafest timeframe within a day. 
It's interesting to remark the high increase in crimes reported in 2019 during the night. We can see that for 2019, the times reported at night are 30%-50%  higher than those in 2017 and 2018, respectively.
Afterwards, I dived into the types of crimes committed during each year.

```{r}

CrimeYears <- Crimes_BA17 %>% 
  group_by(year, tipo_delito) %>% 
  na.omit() %>% 
  count() 

CrimeYears2 <- Crimes_BA18 %>% 
  group_by(year, tipo_delito) %>% 
  na.omit() %>% 
  count() 

CrimeYears4 <- Crimes_BA19 %>% 
   group_by(year, tipo_delito) %>% 
  na.omit() %>% 
  count() 

CrimeYears3 <- full_join(CrimeYears, CrimeYears2)

CrimeYears <- full_join(CrimeYears4, CrimeYears3)

CrimeYears %>% 
  ggplot(aes(x = year, y = n, color = tipo_delito, fill = tipo_delito))+
    scale_fill_discrete(labels = c('Murder', "Non-violent theft", "Injuries", "Violent Robbery"))+
      scale_color_discrete(labels = c('Murder', "Non-violent theft", "Injuries", "Robbery"))+
  geom_col(position="dodge")+
theme_bw()+
      ylab("Number of Crimes")+
  xlab("Year")+
    theme(legend.position= "right")+
  labs(fill = "Crime Category")+
  labs(color = "Crime Category")
  plot_annotation(title = "Crimes' Categories in the City of Buenos Aires",theme=theme(plot.title = element_text(size=9))) & theme(text=element_text("mono"))

```

From the graph above we can see that from 2017 to 2019, the types of crimes committed are distributed equally: in the first place, the most committed crime is "violent robbery", followed by "non-violent theft", injuries and murders.

In a City as extense as Buenos Aires-bearing in mind we are just considering the Autonomous City of Buenos Aires (CABA)- that extends in a territory of 203 km2, I was curious about the safer and unsafest areas. 
Being such a big city, it's divided by "Comunas" that are at the same time divided in "barrios" therefore neighborhoods. For getting insights on the topic I could either control the variable "Comuna" or the variable "Barrio". I thought that for the scope of this project, it was smarter to control the former than the latter, since showing an area that comprehends diverse neighborhoods is more representative than just scattered neighborhoods around.


```{r}
SafeArea17 <- Crimes_BA17  %>%
  group_by(comuna) %>% 
  count() %>% 
  ggplot(aes(x = comuna, y = n, fill = comuna == "1" | comuna == "4" | comuna == "14" ),position = "dodge")+
  geom_col()+  
  xlim(0,15)+
    ylim(0,20000)+
      scale_x_continuous(breaks = seq(1,15, by = 2))+
    ylab("Number of Crimes Committed")+
        xlab(" ")+
    ggtitle("2017")+
    theme(legend.position = "none", axis.text.x=element_text(size=rel(0.8)))

SafeArea18 <- Crimes_BA18  %>%
  group_by(comuna) %>% 
  count() %>% 
  ggplot(aes(x = comuna, y = n, fill = comuna == "1" | comuna == "3" | comuna == "4" ), position = "dodge")+
  geom_col()+
    ylim(0,20000)+
        scale_x_continuous(breaks = seq(1,15, by = 2))+
    xlab("Comuna")+
  ylab(" ")+
    ggtitle("2018")+
    theme(legend.position = "none", axis.text.x=element_text(size=rel(0.8)))

SafeArea19 <- Crimes_BA19  %>%
  group_by(comuna) %>% 
  count() %>% 
 ggplot(aes(x = comuna, y = n, fill = comuna == "1" | comuna == "3" | comuna == "4" ), position = "dodge")+
  geom_col()+
    xlab(" ")+
  ylab(" ")+
  ylim(0,20000)+
  ggtitle("2019")+
          scale_x_continuous(breaks = seq(1,15, by = 2))+
    theme(legend.position = "none", axis.text.x=element_text(size=rel(0.8)))

Graph_SafeArea <-  ( SafeArea17 | SafeArea18 |SafeArea19)

Graph_SafeArea + plot_annotation(
  title = 'Crimes Committed by Comuna in City of Buenos Aires', theme=theme(plot.title=element_text(size=9))) & theme(text=element_text("mono"))
```

As we can see, the most dangerous Comunas in the city of Buenos Aires are the first, third, fourth and fourteenth comuna.
For representing this graphically I thought it could be interesting to include some map representations on my Capstone Project. To do so, I installed the libraries leaflet, maps, leaflet.extras, leafsync and rmdfiltr. By specifying latitude and longitude I could obtain the Map of the City of Buenos Aires.
I looked up for the coordinates of each comuna online and used a function within the radius of each year's quantity of crimes to represent the variations geographically from one year to the other.

```{r}

Unsafest17 <- read.csv(textConnection("
Comuna,Lat,Long,N
1,-34.6152,-58.3738,16281		
4,-34.6493,-58.3964,10554	
14,-34.5889, -58.4306,10008	
"))

Unsafest18 <- read.csv(textConnection("
Comuna,Lat,Long,N
1,-34.6152,-58.3738,16736	
3,-34.6107,-58.4068,10430
4,-34.6493,-58.3964,9616	
"))

Unsafest19 <- read.csv(textConnection("
Comuna,Lat,Long,N
1,-34.6152,-58.3738,19452
3,-34.6107,-58.4068,11498	
4,-34.6493,-58.3964,10295
"))


Map17 <- leaflet(Unsafest17) %>% 
  addTiles() %>%
  addCircles(lng = ~Long, lat = ~Lat, weight = 1,
    radius = ~sqrt(N) * 10, popup = ~Comuna
  )

Map17 

Map18 <- leaflet(Unsafest18) %>% 
  addTiles() %>%
  addCircles(lng = ~Long, lat = ~Lat, weight = 1,
    radius = ~sqrt(N) * 10, popup = ~Comuna
  )

Map18

Map19 <- leaflet(Unsafest19) %>% 
  addTiles() %>%
  addCircles(lng = ~Long, lat = ~Lat, weight = 1,
    radius = ~sqrt(N) * 10, popup = ~Comuna
  )

Map19
```

<h4>4.Conclusions</h4>

After analyzing the datasets of safety in Buenos Aires from 2017 to 2019, we can agree that there is a consistent level of unsafety in the city, with a steady distribution along the years - over 120000 crimes reported per year. 

Giving that: 
- The average of the crimes reported in the period analyzed equals  122260
- The inhabitants of the city of Buenos Aires to be 2.890.151, as reported in the last national census in 2010 

We can conclude that each inhabitant in the city of Buenos Aires has a probability of 4.23% to be victim of a crime.

All in all, we can conclude there is a more or less normal distribution regarding the number of crimes and the time of the year these happened - since there are no extraordinary variations along the months  of the year. But we can say there are variations towards the time of the day the crime is committed and the area of the city.
Regarding safe timeframes, we can conclude that safety levels decrease during the afternoon and night - seeing a noteworthy increase in the crimes committed during the latter in 2019 - and that geographically speaking, the areas where the majority of the crimes happen are the Comuna 1, 3, 4 and 14.
It's important to mention that these areas represent urban focuses within the city of Buenos Aires constituting central areas where companies, offices, stores and state buildings are located. 
As per continuing the research and development of the project it would be valuable to download the dataset of Crimes reported in 2020 once it is available. In the context of COVID-19 and considering 2020 to be a very particular moment in history, I would be curious to detect variations respecting the quantity of the crimes committed as well as the geographical distribution of these. As a first hypothesis towards proposing the ongoing development of this study, I would say crimes may have decreased during the pandemic period and that areas might have changed as a result of people staying at home and not transitting commercial areas. 
To conclude, I would like this project to become a source of awareness for the citizens of the City of Buenos Aires. I imagine interactive dashboards, graphs and maps as digital advertisements around the city in order to raise awareness on unsafety and promote a transparent treatment of data.

Word Count excluding code chunks and inline code:

```{r}
wordcountaddin::word_count("Capstone-Project-CatalinaMasPohmajevic.Rmd")
```
